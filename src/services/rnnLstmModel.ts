import * as tf from '@tensorflow/tfjs';
import { DrawResult } from './lotteryAPI';
import { MLPrediction, ModelMetrics, FeatureEngineering } from './mlModels';

/**
 * Mod√®le RNN-LSTM avec GRU pour la pr√©diction de s√©quences temporelles
 * Utilise TensorFlow.js pour l'entra√Ænement et les pr√©dictions
 */
export class RNNLSTMModel {
  private model: tf.LayersModel | null = null;
  private sequenceLength = 10;
  private hiddenUnits = 64;
  private numFeatures = 12;
  private trained = false;
  private scaler: { mean: tf.Tensor; std: tf.Tensor } | null = null;

  constructor(
    sequenceLength = 10,
    hiddenUnits = 64
  ) {
    this.sequenceLength = sequenceLength;
    this.hiddenUnits = hiddenUnits;
  }

  /**
   * Entra√Æne le mod√®le RNN-LSTM/GRU sur les donn√©es historiques
   */
  async train(results: DrawResult[]): Promise<void> {
    console.log('üß† Entra√Ænement du mod√®le RNN-LSTM/GRU...');
    
    if (results.length < this.sequenceLength + 5) {
      throw new Error('Pas assez de donn√©es pour l\'entra√Ænement du RNN');
    }

    try {
      // Pr√©paration des donn√©es
      const trainingData = this.prepareSequentialData(results);
      if (trainingData.sequences.length === 0) {
        throw new Error('Aucune s√©quence valide g√©n√©r√©e');
      }

      // Cr√©ation du mod√®le
      this.model = this.createModel();

      // Normalisation des donn√©es
      this.scaler = this.createScaler(trainingData.sequences);
      const normalizedSequences = this.normalizeData(trainingData.sequences, this.scaler);
      const normalizedTargets = this.normalizeTargets(trainingData.targets, this.scaler);

      // Conversion en tensors TensorFlow
      const xTrain = tf.tensor3d(normalizedSequences);
      const yTrain = tf.tensor2d(normalizedTargets);

      console.log(`üìä Entra√Ænement sur ${trainingData.sequences.length} s√©quences`);

      // Entra√Ænement du mod√®le
      const history = await this.model.fit(xTrain, yTrain, {
        epochs: 50,
        batchSize: Math.min(32, Math.floor(trainingData.sequences.length / 4)),
        validationSplit: 0.2,
        shuffle: true,
        verbose: 0,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            if (epoch % 10 === 0) {
              console.log(`Epoch ${epoch}: loss=${logs?.loss?.toFixed(4)}, val_loss=${logs?.val_loss?.toFixed(4)}`);
            }
          }
        }
      });

      // Nettoyage des tensors
      xTrain.dispose();
      yTrain.dispose();

      this.trained = true;
      console.log('‚úÖ Mod√®le RNN-LSTM entra√Æn√© avec succ√®s');

    } catch (error) {
      console.error('‚ùå Erreur lors de l\'entra√Ænement RNN-LSTM:', error);
      throw error;
    }
  }

  /**
   * G√©n√®re des pr√©dictions avec le mod√®le entra√Æn√©
   */
  predict(results: DrawResult[], targetCount = 5): MLPrediction[] {
    if (!this.trained || !this.model || !this.scaler) {
      throw new Error('Le mod√®le RNN-LSTM doit √™tre entra√Æn√© avant les pr√©dictions');
    }

    try {
      const predictions: MLPrediction[] = [];
      
      // Pr√©parer la s√©quence d'entr√©e (derni√®res donn√©es)
      const inputSequence = this.prepareInputSequence(results);
      const normalizedInput = this.normalizeData([inputSequence], this.scaler);
      
      const inputTensor = tf.tensor3d(normalizedInput);
      
      // Pr√©diction pour chaque num√©ro
      for (let number = 1; number <= 90; number++) {
        // Cr√©er un contexte pour ce num√©ro sp√©cifique
        const numberContext = this.createNumberContext(inputSequence, number);
        const contextTensor = tf.tensor3d([numberContext]);
        
        // Pr√©diction probabiliste
        const predictionTensor = this.model.predict(contextTensor) as tf.Tensor;
        const predictionData = predictionTensor.dataSync();
        const predictionArray = Array.from(predictionData);
        
        // Interpr√©ter la pr√©diction
        const rawProbability = predictionArray[0];
        const probability = this.sigmoid(rawProbability);
        
        // Calcul de la confiance bas√©e sur la consistance du mod√®le
        const confidence = this.calculateConfidence(probability, inputSequence, number);
        
        // Estimation d'incertitude
        const uncertainty = 1 - confidence;

        predictions.push({
          number,
          probability,
          confidence,
          uncertainty,
          features: ['S√©quences temporelles', 'Patterns RNN', 'Tendances GRU']
        });

        // Nettoyage
        contextTensor.dispose();
        predictionTensor.dispose();
      }

      inputTensor.dispose();

      // Trier par probabilit√© d√©croissante et retourner les meilleurs
      return predictions
        .sort((a, b) => b.probability - a.probability)
        .slice(0, targetCount);

    } catch (error) {
      console.error('‚ùå Erreur lors de la pr√©diction RNN-LSTM:', error);
      throw error;
    }
  }

  /**
   * √âvalue les performances du mod√®le
   */
  async evaluate(testResults: DrawResult[]): Promise<Partial<ModelMetrics>> {
    if (!this.trained || !this.model) {
      throw new Error('Mod√®le non entra√Æn√©');
    }

    const predictions = this.predict(testResults.slice(0, -1), 10);
    const actualNumbers = testResults[testResults.length - 1].gagnants;
    
    // Calculer la pr√©cision
    const predictedNumbers = predictions.slice(0, 5).map(p => p.number);
    const correctPredictions = predictedNumbers.filter(num => actualNumbers.includes(num));
    const accuracy = correctPredictions.length / 5;

    return {
      accuracy,
      precision: accuracy,
      recall: correctPredictions.length / actualNumbers.length,
      f1Score: accuracy > 0 ? (2 * accuracy * accuracy) / (2 * accuracy) : 0
    };
  }

  /**
   * Cr√©e l'architecture du mod√®le RNN-LSTM/GRU
   */
  private createModel(): tf.LayersModel {
    const model = tf.sequential({
      layers: [
        // Couche GRU principale pour capturer les patterns temporels
        tf.layers.gru({
          units: this.hiddenUnits,
          returnSequences: true,
          inputShape: [this.sequenceLength, this.numFeatures],
          recurrentDropout: 0.2,
          dropout: 0.2
        }),
        
        // Couche LSTM pour affiner les pr√©dictions temporelles
        tf.layers.lstm({
          units: this.hiddenUnits / 2,
          returnSequences: false,
          recurrentDropout: 0.2,
          dropout: 0.2
        }),
        
        // Couches denses avec r√©gularisation
        tf.layers.dense({
          units: 32,
          activation: 'relu',
          kernelRegularizer: tf.regularizers.l2({ l2: 0.001 })
        }),
        tf.layers.dropout({ rate: 0.3 }),
        
        tf.layers.dense({
          units: 16,
          activation: 'relu'
        }),
        tf.layers.dropout({ rate: 0.2 }),
        
        // Sortie probabiliste
        tf.layers.dense({
          units: 1,
          activation: 'linear' // Utilisation de sigmoid dans post-traitement
        })
      ]
    });

    // Compilation avec optimiseur Adam
    model.compile({
      optimizer: tf.train.adam(0.001),
      loss: 'meanSquaredError',
      metrics: ['mae']
    });

    return model;
  }

  /**
   * Pr√©pare les donn√©es s√©quentielles pour l'entra√Ænement
   */
  private prepareSequentialData(results: DrawResult[]): {
    sequences: number[][][];
    targets: number[][];
  } {
    const sequences: number[][][] = [];
    const targets: number[][] = [];
    
    // Trier par date
    const sortedResults = results.sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime());
    
    for (let i = 0; i < sortedResults.length - this.sequenceLength - 1; i++) {
      const sequenceResults = sortedResults.slice(i, i + this.sequenceLength);
      const targetResult = sortedResults[i + this.sequenceLength];
      
      // Cr√©er la s√©quence de features
      const sequence = sequenceResults.map(result => this.extractFeatures(result, sortedResults, i));
      
      // Target : repr√©sentation binaire des num√©ros gagnants
      const target = this.createTargetVector(targetResult.gagnants);
      
      sequences.push(sequence);
      targets.push(target);
    }
    
    return { sequences, targets };
  }

  /**
   * Extrait les features temporelles pour un r√©sultat
   */
  private extractFeatures(result: DrawResult, allResults: DrawResult[], index: number): number[] {
    const features: number[] = [];
    
    // Features de base : moyenne et variance des num√©ros
    const mean = result.gagnants.reduce((sum, n) => sum + n, 0) / 5;
    const variance = result.gagnants.reduce((sum, n) => sum + Math.pow(n - mean, 2), 0) / 5;
    
    features.push(mean / 90, variance / 1000); // Normalisation
    
    // Distribution par tranches
    const ranges = [
      [1, 18], [19, 36], [37, 54], [55, 72], [73, 90]
    ];
    
    ranges.forEach(([min, max]) => {
      const count = result.gagnants.filter(n => n >= min && n <= max).length;
      features.push(count / 5);
    });
    
    // Features temporelles (jour de la semaine, position dans le mois)
    const date = new Date(result.date);
    features.push(
      date.getDay() / 7,
      date.getDate() / 31,
      date.getMonth() / 12
    );
    
    // Parit√© et somme
    const evenCount = result.gagnants.filter(n => n % 2 === 0).length;
    const sum = result.gagnants.reduce((a, b) => a + b, 0);
    
    features.push(evenCount / 5, sum / 450);
    
    return features;
  }

  /**
   * Cr√©e un vecteur cible pour l'entra√Ænement
   */
  private createTargetVector(winningNumbers: number[]): number[] {
    // Utiliser une approche de r√©gression pour pr√©dire la probabilit√© moyenne
    const avgNumber = winningNumbers.reduce((sum, n) => sum + n, 0) / winningNumbers.length;
    return [avgNumber / 90]; // Normalisation
  }

  /**
   * Pr√©pare la s√©quence d'entr√©e pour la pr√©diction
   */
  private prepareInputSequence(results: DrawResult[]): number[][] {
    const sortedResults = results
      .sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime())
      .slice(0, this.sequenceLength);
    
    return sortedResults.reverse().map((result, index) => 
      this.extractFeatures(result, results, index)
    );
  }

  /**
   * Cr√©e un contexte sp√©cifique pour un num√©ro
   */
  private createNumberContext(inputSequence: number[][], targetNumber: number): number[][] {
    return inputSequence.map(features => {
      // Ajouter le num√©ro cible comme feature contextuelle
      const contextFeatures = [...features];
      contextFeatures.push(targetNumber / 90); // Normalisation du num√©ro cible
      return contextFeatures.slice(0, this.numFeatures);
    });
  }

  /**
   * Calcule la confiance de la pr√©diction
   */
  private calculateConfidence(probability: number, sequence: number[][], number: number): number {
    // Analyser la fr√©quence historique du num√©ro dans la s√©quence
    let historicalFrequency = 0;
    
    // Calculer une m√©trique de confiance bas√©e sur la consistance
    const consistency = Math.exp(-Math.abs(probability - 0.5) * 2);
    
    return Math.min(0.95, Math.max(0.1, consistency));
  }

  /**
   * Fonction sigmoid
   */
  private sigmoid(x: number): number {
    return 1 / (1 + Math.exp(-x));
  }

  /**
   * Cr√©e un normalisateur pour les donn√©es
   */
  private createScaler(data: number[][][]): { mean: tf.Tensor; std: tf.Tensor } {
    // Aplatir toutes les donn√©es pour calculer mean/std
    const flatData: number[] = [];
    data.forEach(sequence => {
      sequence.forEach(features => {
        flatData.push(...features);
      });
    });
    
    const tensor = tf.tensor1d(flatData);
    const mean = tensor.mean();
    const std = tensor.sub(mean).square().mean().sqrt().add(1e-8);
    
    tensor.dispose();
    
    return { mean, std };
  }

  /**
   * Normalise les donn√©es avec le scaler
   */
  private normalizeData(data: number[][][], scaler: { mean: tf.Tensor; std: tf.Tensor }): number[][][] {
    return data.map(sequence => 
      sequence.map(features => {
        const tensor = tf.tensor1d(features);
        const normalized = tensor.sub(scaler.mean).div(scaler.std);
        const result = Array.from(normalized.dataSync());
        tensor.dispose();
        normalized.dispose();
        return result;
      })
    );
  }

  /**
   * Normalise les targets (diff√©rent des s√©quences)
   */
  private normalizeTargets(data: number[][], scaler: { mean: tf.Tensor; std: tf.Tensor }): number[][] {
    return data.map(targets => {
      const tensor = tf.tensor1d(targets);
      const normalized = tensor.sub(scaler.mean).div(scaler.std);
      const result = Array.from(normalized.dataSync());
      tensor.dispose();
      normalized.dispose();
      return result;
    });
  }

  /**
   * Lib√®re la m√©moire du mod√®le
   */
  dispose(): void {
    if (this.model) {
      this.model.dispose();
      this.model = null;
    }
    if (this.scaler) {
      this.scaler.mean.dispose();
      this.scaler.std.dispose();
      this.scaler = null;
    }
    this.trained = false;
  }

  /**
   * Retourne l'importance des features
   */
  getFeatureImportance(): Map<string, number> {
    const importance = new Map<string, number>();
    
    // Simuler l'importance des features pour RNN-LSTM
    importance.set('Tendances temporelles', 0.25);
    importance.set('Patterns s√©quentiels', 0.20);
    importance.set('Distribution des num√©ros', 0.18);
    importance.set('Cycles temporels', 0.15);
    importance.set('Momentum', 0.12);
    importance.set('R√©gularit√©s', 0.10);
    
    return importance;
  }
}